{
 "metadata": {
  "name": "",
  "signature": "sha256:b649d08ea58f444ad526394601968ce4c69198743e9a429e5e791c8163fbfba0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import math\n",
      "\n",
      "def calc_entropy(activationVector):\n",
      "    entropy=0.0\n",
      "    summation = np.sum(activationVector)\n",
      "    activationVector = activationVector / summation\n",
      "    for val in activationVector:\n",
      "        entropy = entropy - val * math.log(val,2)\n",
      "    return entropy\n",
      "\n",
      "speakers = '050'\n",
      "noises = 'clean car babble restaurant street airport train'\n",
      "channels = 'wv1'   #TODO wv2\n",
      "layer_size = 2048\n",
      "\n",
      "speakerList = speakers.split()\n",
      "noisesList = noises.split()\n",
      "channelList = channels.split()\n",
      "\n",
      "num_noises = len(noisesList) \n",
      "max_entropy = num_noises * -(1.0/num_noises)* math.log(1.0/num_noises ,2)\n",
      "\n",
      "act_base = 'sensitivity/activations/dev_0330/'\n",
      "\n",
      "\n",
      "for layer in range(1,2):\n",
      "    for speaker in speakerList:\n",
      "        for channel in channelList:\n",
      "            \n",
      "            #Currently, the sensitivity is analyzed per-speaker, per-channel\n",
      "            noise_counts={}\n",
      "            noise_vectors={}\n",
      "            for noise in noisesList:\n",
      "                frame_count = 0\n",
      "                activation_file = open(act_base+ speaker+'/'+channel+'/'+noise+'/'+layer+'_activations.ark','r')\n",
      "                for line in activation_file:\n",
      "                    act_line = (line.rstrip()).split()\n",
      "                    if len(act_line) == 2:\n",
      "                                utt1= act_line[0]\n",
      "                                #print ' started reading hidden activations for ' + act_line[0]\n",
      "                    elif len(act_line) == layer_size + 1:\n",
      "                        frame_count =frame_count + 1\n",
      "                        if noise in noise_vectors.keys():\n",
      "                            noise_vectors[noise] = np.add(np.array(act_line[:layer_size],dtype=np.float),noise_vectors.get(noise))\n",
      "                        else:\n",
      "                            noise_vectors[noise] = np.array(act_line[:layer_size],dtype=np.float)\n",
      "                    else:\n",
      "                        frame_count =frame_count + 1\n",
      "                        if noise in noise_vectors.keys():\n",
      "                            noise_vectors[noise] = np.add(np.array(act_line,dtype=np.float),noise_vectors.get(noise))\n",
      "                        else:\n",
      "                            noise_vectors[noise] = np.array(act_line,dtype=np.float)\n",
      "                noise_counts[noise]=frame_count\n",
      "                print 'frame count for noise %s is %d'%(noise,frame_count)\n",
      "            \n",
      "            #Average noise activation vectors\n",
      "            for noise in noise_counts.keys():\n",
      "                noise_vectors[noise] = noise_vectors.get(noise)/noise_counts.get(noise)\n",
      "                \n",
      "            weight_array=np.zeros(layer_size)\n",
      "            for noise in noise_vectors.keys():\n",
      "                weight_array=np.vstack((weight_array,noise_vectors.get(noise)))\n",
      "            \n",
      "            weight_array = np.delete(weight_array,0,0)\n",
      "            \n",
      "            ent_val=[]\n",
      "            for i in range(layer_size):\n",
      "                ent_val.append(calc_entropy(weight_array[:,i]))\n",
      "\n",
      "            #print len(ent_val)\n",
      "            total_ent=0.0\n",
      "            sens_val={}\n",
      "            node_idx=0\n",
      "            for ent in ent_val :\n",
      "                sens = (max_entropy - ent)/max_entropy\n",
      "                total_ent = total_ent + sens\n",
      "                sens_val[node_idx]=sens\n",
      "                node_idx = node_idx + 1\n",
      "            \n",
      "            print total_ent/layer_size\n",
      "            \n",
      "            #get the most sensitive units\n",
      "#             keys = sorted(sens_val.keys(),reverse=True)\n",
      "            #print len(spk_keys)\n",
      "\n",
      "            sens_units=[]\n",
      "            for key in sorted(sens_val,key=sens_val.get,reverse=True):\n",
      "                sens_units.append(key)\n",
      "                \n",
      "#             for i in range(layer_size):\n",
      "#                 sens_units.append(sens_val.get(keys[i]))\n",
      "            \n",
      "            #overall = (max_entropy - sum(ent_val)/layer_size)/max_entropy\n",
      "            np.savetxt(act_base+ speaker+'/'+channel+'/'+'noiseSensitivity%d'%layer,sens_val.values())\n",
      "            np.savetxt(act_base+ speaker+'/'+channel+'/'+'noiseUnits%d'%layer,sens_units)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}